[2023-01-27 16:02:31,796] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_local_gcs_GroupID06.amazon_gcs_to_bigquery manual__2023-01-27T16:02:12.125710+00:00 [queued]>
[2023-01-27 16:02:31,805] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_local_gcs_GroupID06.amazon_gcs_to_bigquery manual__2023-01-27T16:02:12.125710+00:00 [queued]>
[2023-01-27 16:02:31,806] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2023-01-27 16:02:31,806] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2023-01-27 16:02:31,807] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2023-01-27 16:02:31,815] {taskinstance.py:1259} INFO - Executing <Task(GCSToBigQueryOperator): amazon_gcs_to_bigquery> on 2023-01-27 16:02:12.125710+00:00
[2023-01-27 16:02:31,823] {standard_task_runner.py:52} INFO - Started process 529 to run task
[2023-01-27 16:02:31,828] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_local_gcs_GroupID06', 'amazon_gcs_to_bigquery', 'manual__2023-01-27T16:02:12.125710+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_local_gcs_GroupID06.py', '--cfg-path', '/tmp/tmpf6wzl0cs', '--error-file', '/tmp/tmp0z92913l']
[2023-01-27 16:02:31,828] {standard_task_runner.py:77} INFO - Job 5: Subtask amazon_gcs_to_bigquery
[2023-01-27 16:02:31,880] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_local_gcs_GroupID06.amazon_gcs_to_bigquery manual__2023-01-27T16:02:12.125710+00:00 [running]> on host fdab5790e71d
[2023-01-27 16:02:31,926] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_local_gcs_GroupID06
AIRFLOW_CTX_TASK_ID=amazon_gcs_to_bigquery
AIRFLOW_CTX_EXECUTION_DATE=2023-01-27T16:02:12.125710+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-01-27T16:02:12.125710+00:00
[2023-01-27 16:02:31,928] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/providers/google/cloud/transfers/gcs_to_bigquery.py:261: DeprecationWarning: The bigquery_conn_id parameter has been deprecated. You should pass the gcp_conn_id parameter.
  impersonation_chain=self.impersonation_chain,

[2023-01-27 16:02:31,930] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2023-01-27 16:02:31,932] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/providers/google/cloud/hooks/bigquery.py:141: DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
  "This method will be deprecated. Please use `BigQueryHook.get_client` method", DeprecationWarning

[2023-01-27 16:02:33,279] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/models/taskinstance.py:1511: DeprecationWarning: This method is deprecated. Please use `***.providers.google.cloud.hooks.bigquery.BigQueryHook.run_load`
  result = execute_callable(context=context)

[2023-01-27 16:02:33,280] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/providers/google/cloud/hooks/bigquery.py:1772: DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
  "This method is deprecated. Please use `BigQueryHook.insert_job` method.", DeprecationWarning

[2023-01-27 16:02:33,282] {bigquery.py:1637} INFO - Inserting job ***_1674835353281794_38cf88bacfd19bb9ca3f54ae23d4ec77
[2023-01-27 16:02:41,991] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_local_gcs_GroupID06, task_id=amazon_gcs_to_bigquery, execution_date=20230127T160212, start_date=20230127T160231, end_date=20230127T160241
[2023-01-27 16:02:42,056] {local_task_job.py:154} INFO - Task exited with return code 0
[2023-01-27 16:02:42,088] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
